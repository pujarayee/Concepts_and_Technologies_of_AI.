{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, learning_rate=0.01, iterations=1000):\n",
        "\n",
        "    m = len(y)  # Number of samples\n",
        "    n = X.shape[1]  # Number of features\n",
        "    W = np.zeros(n)  # Initialize weights to zero\n",
        "    costs = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Calculate predictions\n",
        "        Y_pred = X @ W\n",
        "\n",
        "        # Calculate errors\n",
        "        errors = Y_pred - y\n",
        "\n",
        "        # Calculate the cost (Mean Squared Error)\n",
        "        cost = (1 / (2 * m)) * np.sum(errors ** 2)\n",
        "        costs.append(cost)\n",
        "\n",
        "\n",
        "        # Calculate gradients\n",
        "        gradients = (1 / m) * (X.T @ errors)\n",
        "\n",
        "        # Update weights\n",
        "        W = W - learning_rate * gradients\n",
        "\n",
        "    return W, costs"
      ],
      "metadata": {
        "id": "OGSCNap1mmh1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define rsme\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def rmse(y_true, y_predicted):\n",
        "  mse = np.mean((y_true - y_predicted)**2)\n",
        "  rmse = np.sqrt(mse)\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "TGS071vgmjP4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define data\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Dataset/student.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'student.csv' not found. Please provide the correct file path.\")\n",
        "    exit() # or handle the error in a different way\n"
      ],
      "metadata": {
        "id": "XQt4XAXGmfNb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def gradient_descent(X, y, learning_rate=0.01, iterations=1000):\n",
        "    m = len(y)  # Number of samples\n",
        "    n = X.shape[1]  # Number of features\n",
        "    W = np.zeros(n)  # Initialize weights to zero\n",
        "    costs = []\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        # Calculate predictions\n",
        "        Y_pred = X @ W\n",
        "\n",
        "        # Calculate errors\n",
        "        errors = Y_pred - y\n",
        "\n",
        "        # Calculate the cost (Mean Squared Error)\n",
        "        cost = (1 / (2 * m)) * np.sum(errors ** 2)\n",
        "        costs.append(cost)\n",
        "\n",
        "\n",
        "        # Calculate gradients\n",
        "        gradients = (1 / m) * (X.T @ errors)\n",
        "\n",
        "        # Update weights\n",
        "        W = W - learning_rate * gradients\n",
        "\n",
        "    return W, costs\n",
        "# define rsme\n",
        "\n",
        "\n",
        "def rmse(y_true, y_predicted):\n",
        "  mse = np.mean((y_true - y_predicted)**2)\n",
        "  rmse = np.sqrt(mse)\n",
        "  return rmse\n",
        "# define data\n",
        "\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Dataset/student.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'student.csv' not found. Please provide the correct file path.\")\n",
        "    exit() # or handle the error in a different way\n",
        "\n",
        "# Define x (features)\n",
        "x = df[['Math', 'Reading']]\n",
        "x = np.array(x)\n",
        "# Add bias term to x\n",
        "X = np.concatenate((np.ones((x.shape[0], 1)), x), axis=1)\n",
        "\n",
        "y = df['Writing']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "1tFS4M0WmwgY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Writing']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "8Sp_M986nSVk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define r2\n",
        "\n",
        "def r2(y_true, y_predicted):\n",
        "    # Calculate the mean of the true values\n",
        "    mean_y_true = np.mean(y_true)\n",
        "\n",
        "    # Calculate the total sum of squares (TSS)\n",
        "    TSS = np.sum((y_true - mean_y_true)**2)\n",
        "\n",
        "    # Calculate the residual sum of squares (RSS)\n",
        "    RSS = np.sum((y_true - y_predicted)**2)\n",
        "\n",
        "    # Calculate R-squared\n",
        "    r2 = 1 - (RSS / TSS)\n",
        "\n",
        "    return r2"
      ],
      "metadata": {
        "id": "2Sxxp4LlnpeG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define y\n",
        "\n",
        "y = df['Writing']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "peuFpGsXoRko"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEN-EPhfmBLo",
        "outputId": "a666c78f-45b6-446b-ec42-ecea3f7cf4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Weights: [0.34811659 0.64614558]\n",
            "Cost History (First 10 iterations): [2471.69875, 2013.165570783755, 1640.286832599692, 1337.0619994901588, 1090.479489285058, 889.9583270083235, 726.8940993009545, 594.2897260808594, 486.4552052951634, 398.7634463599482]\n",
            "RMSE on Test Set: 5.2798239764188635\n",
            "R-Squared on Test Set: 0.8886354462786421\n"
          ]
        }
      ],
      "source": [
        "# Main Function\n",
        "def main():\n",
        "  # Step 1: Load the dataset\n",
        "  data = pd.read_csv('/content/drive/MyDrive/Dataset/student.csv')\n",
        "  # Step 2: Split the data into features (X) and target (Y)\n",
        "  X = data[['Math', 'Reading']].values # Features: Math and Reading marks\n",
        "  Y = data['Writing'].values # Target: Writing marks\n",
        "  # Step 3: Split the data into training and test sets (80% train, 20% test)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "  # Step 4: Initialize weights (W) to zeros, learning rate and number of iterations\n",
        "  W = np.zeros(X_train.shape[1]) # Initialize weights\n",
        "  alpha = 0.00001 # Learning rate\n",
        "  iterations = 1000 # Number of iterations for gradient descent\n",
        "  # Step 5: Perform Gradient Descent\n",
        "  W_optimal, cost_history = gradient_descent(X_train, Y_train, W, alpha, iterations)\n",
        "  # Step 6: Make predictions on the test set\n",
        "  Y_pred = np.dot(X_test, W_optimal)\n",
        "  # Step 7: Evaluate the model using RMSE and R-Squared\n",
        "  model_rmse = rmse(Y_test, Y_pred)\n",
        "  model_r2 = r2(Y_test, Y_pred)\n",
        "  # Step 8: Output the results\n",
        "  print(\"Final Weights:\", W_optimal)\n",
        "  print(\"Cost History (First 10 iterations):\", cost_history[:10])\n",
        "  print(\"RMSE on Test Set:\", model_rmse)\n",
        "  print(\"R-Squared on Test Set:\", model_r2)\n",
        "# Execute the main function\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Present your finding:\n",
        "1. Did your Model Overfitt, Underfitts, or performance is acceptable.\n",
        "2. Experiment with different value of learning rate, making it higher and lower, observe the result."
      ],
      "metadata": {
        "id": "TyEl9tHZp8v4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting: If the R² on the test set were much lower than on the training set, it would indicate overfitting.\n",
        "\n",
        "Underfitting: If the R² were significantly below 0.7, the model might underfit.\n",
        "\n",
        "Since the test set R² is high (0.89) and the RMSE is reasonable, the model generalizes well without showing symptoms of overfitting or underfitting.\n",
        "The model's performance is acceptable and reflects a good balance between bias and variance"
      ],
      "metadata": {
        "id": "4IOdIc1sp_HA"
      }
    }
  ]
}